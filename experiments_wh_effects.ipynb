{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdde30b-25c9-4b3c-88b8-2a19a2816d08",
   "metadata": {},
   "source": [
    "# PiPP wh-effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9979fbb8-6e49-4932-9133-c0e733df8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8638902-dd6b-48c9-aad9-20f241bc6c06",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0852ef59-4bd6-40b8-8d10-5291e925c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7155fd11-dd42-405d-a6c8-d4e7f5bb4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"pipp.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d3a1b7-2290-40e3-8607-4eb401aacc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1b4f7-5d34-4be7-9c24-9d343368c328",
   "metadata": {},
   "source": [
    "## Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34afd0f3-b6c1-4478-910e-058267ef69d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PiPP (Filler/Gap)': ('Happy though we were with the idea, we had to reject it.',\n",
       "  'with'),\n",
       " 'PP (No Filler/No Gap)': ('Though we were happy with the idea, we had to reject it.',\n",
       "  'happy'),\n",
       " 'Filler/No Gap': ('Happy though we were happy with the idea, we had to reject it.',\n",
       "  'happy'),\n",
       " 'No Filler/Gap': ('Though we were with the idea, we had to reject it.',\n",
       "  'with')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.item(\"Happy* though we were GAP with the idea, we had to reject it.\", \n",
    "     embedding=\"\", \n",
    "     preposition=\"though\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903d0a3-0e75-41ca-a743-3381a2d714ba",
   "metadata": {},
   "source": [
    "## Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdfeb52-d0ce-4a76-9f61-50f9a3bcd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"materials.txt\") as f:\n",
    "    materials = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9f78e-2bef-4310-8f21-6affbdda532b",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28be26c7-5876-4615-a3b3-a1789a98598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_item(ex, item_num, model_func, embedding=\"\", preposition=\"though\"):\n",
    "    data = []\n",
    "    conds = utils.item(ex, embedding=embedding, preposition=preposition)\n",
    "    for typ, (text, target) in conds.items():\n",
    "        response = model_func([text])\n",
    "        ti = [i for i, tok in enumerate(response['prompt_tokens']) if tok.strip() == target][0]\n",
    "        surprisal = convert_to_surprisal(response['prompt_scores'][ti])\n",
    "        response['condition'] = typ\n",
    "        response['target_surprisal'] = surprisal\n",
    "        response['item_num'] = item_num\n",
    "        data.append(response)\n",
    "    return data\n",
    "\n",
    "def convert_to_surprisal(x):\n",
    "    return -(x / np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49243e2-9a5e-415b-8e66-d012dee98db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(materials, model_func, embedding=\"\", preposition=\"though\", model_name=\"text-davinci-003\"):\n",
    "    data = []\n",
    "    for item_num, m in enumerate(materials, start=1):\n",
    "        data += run_item(m, item_num, model_func, embedding=embedding, preposition=preposition)\n",
    "    emb = f\"-{embedding.replace(' ', '_')}\" if embedding else \"\"\n",
    "    output_filename = f\"results/results-{model_name}-{preposition}{emb}.json\"\n",
    "    with open(output_filename, \"wt\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45c6ea-9d2a-4a8a-9383-96cd00f67162",
   "metadata": {},
   "source": [
    "### GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c0659a-e872-4029-9494-0ad0f13d906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in (\"ada\", \"text-davinci-001\", \"text-davinci-003\"):\n",
    "    for embedding in (\"\", \"they said that we knew that\"):\n",
    "        for prep in (\"though\", \"as\", \"asas\"):\n",
    "            model_func = (lambda prompts: utils.run_gpt3(prompts, engine=engine))\n",
    "            run_experiment(materials, model_func, embedding=embedding, preposition=prep, model_name=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4dbe7-4b58-4c7a-aa74-cd202dbebfab",
   "metadata": {},
   "source": [
    "### GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6444feeb-d8eb-47b8-a8ef-306f8dd6dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer, gpt2_model = utils.load_hugging_face_model(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26bd3fd0-a544-4745-8ea2-1f97a3a972a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding in (\"\", \"they said that we knew that\"):\n",
    "    for prep in (\"though\", \"as\", \"asas\"):\n",
    "        model_func = (lambda prompts: utils.run_hugging_face_autoregressive(prompts, gpt2_tokenizer, gpt2_model))\n",
    "        run_experiment(materials, model_func, embedding=embedding, preposition=prep, model_name=\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219a605-ce4e-4399-a151-917ecdeb0c31",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6501148d-fc90-4636-ba55-a5fd7da35d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_plot(filename, xlim=14):\n",
    "    df = pd.read_json(filename)\n",
    "\n",
    "    order = ['PiPP (Filler/Gap)',  'No Filler/Gap', 'Filler/No Gap', 'PP (No Filler/No Gap)'][::-1]\n",
    "\n",
    "    mus = df.groupby(\"condition\")['target_surprisal'].mean()\n",
    "    mus = mus.loc[order]\n",
    "\n",
    "    cis = df.groupby(\"condition\")['target_surprisal'].apply(utils.get_cis)\n",
    "    cis = cis.loc[order]\n",
    "    cis = np.array([np.array(x) for x in cis.values])\n",
    "\n",
    "    gapless_color = \"#a1def0\"\n",
    "    gap_color = \"#881d2a\"\n",
    "\n",
    "    ax = mus.plot.barh(\n",
    "        xerr=cis.T,\n",
    "        figsize=(8, 5),\n",
    "        color=[gapless_color, gapless_color, gap_color, gap_color])\n",
    "\n",
    "    ax.set_xlabel(\"Mean surprisal\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlim([0, xlim])\n",
    "\n",
    "    add_wh_effect(ax, mus.iloc[1], mus.iloc[0], 0.5, gapless_color)\n",
    "    add_wh_effect(ax, mus.iloc[3], mus.iloc[2], 2.5, gap_color)\n",
    "\n",
    "    output_filename = filename.replace(\".json\", \".pdf\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_filename, dpi=500)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def add_wh_effect(ax, v1, v2, yval, color, nudge=0.2):\n",
    "    effect = v1 - v2\n",
    "    xpos = max([v1, v2]) + nudge\n",
    "    val = \"${}{:.2f}$\".format(\"+\" if effect > 0 else \"\", effect)\n",
    "    ax.plot([v2, v1], [yval, yval], lw=3, linestyle=\"dotted\", color=color)\n",
    "    ax.text(xpos, yval, val, va='center', color='black', fontsize=16, ha='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b58b10f-daad-4c2c-957e-38ad3d0ef3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for results_filename in glob.glob(os.path.join(\"results\", \"*.json\")):\n",
    "    xlim = 24 if \"davinci\" in results_filename else 20\n",
    "    mean_plot(results_filename, xlim=xlim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
