{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2199d76-8fd7-4763-975c-218e5274d525",
   "metadata": {},
   "source": [
    "# BookCorpusOpen searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9a3d1-302b-45d3-abf5-f49a080fdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3d9b2-ba33-4ff0-a9d3-f6d70580a5c8",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bedcea8-6cec-4c55-b127-550ec13f7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcad65-c540-4bbd-9a67-e19aef793679",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS_HOME = \"books1/epubtxt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67dca52-0ab6-4b1a-85bf-f63ab6189f7d",
   "metadata": {},
   "source": [
    "## Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22ff30-3efb-4d6e-90b7-1ae1dc04c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counts(filename):\n",
    "    from nltk.tokenize import TreebankWordTokenizer\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    wc = 0\n",
    "    with open(filename) as f:\n",
    "        wc += len(tokenizer.tokenize(f.read()))\n",
    "    return wc\n",
    "\n",
    "def word_counts_parallel(dirname=BOOKS_HOME):\n",
    "    filenames = glob.glob(os.path.join(dirname, \"*.epub.txt\"))\n",
    "    pbar = tqdm.tqdm(filenames)\n",
    "    data = Parallel(n_jobs=10)(delayed(word_counts)(f) for f in pbar)\n",
    "    return sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d9b4a-c56e-47ba-a529-c182dfabfc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63941187-f14c-4a56-8caf-efce87c39343",
   "metadata": {},
   "source": [
    "## Sentences with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b0121-9ffc-4e5e-88a3-f6cb70255e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def books_reader(filename):\n",
    "    sent_count = 0\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        sents = sent_tokenize(f.read())\n",
    "        sent_count += len(sents)\n",
    "        for sent in sents:\n",
    "            if utils.is_match(sent):\n",
    "                data.append({\"filename\": os.path.basename(filename), \"sentence\": sent})\n",
    "    return sent_count, data\n",
    "\n",
    "def books_reader_parallel(dirname=BOOKS_HOME):\n",
    "    filenames = glob.glob(f\"{dirname}/*.epub.txt\")\n",
    "    pbar = tqdm.tqdm(filenames)\n",
    "    data = Parallel(n_jobs=10)(delayed(books_reader)(f) for f in pbar)\n",
    "    sent_count = sum([c for c, _ in data])\n",
    "    examples = []\n",
    "    for _, exs in data:\n",
    "        examples += exs\n",
    "    return sent_count, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f1100-dd3e-4484-b247-c2a2702c815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_count, matches = books_reader_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc07d7c-1916-4ae4-80af-d1390b99d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eae884-c4b2-40c2-ba01-c6fddd0b0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3dda7-79f3-4bc1-9769-86a272857c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46dad7-62fc-40ba-aeea-e7acc3220f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1.0, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b17cb-5b3c-4228-81b7-97edd9b7bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"samples/pipp-bookcorpusopen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5c74a-2c1a-4b01-9129-b5f841059ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.iloc[: 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430f593-dd39-4c1b-bd9e-3d4b2998915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"samples/pipp-sample-bookcorpusopen.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
